# main pipeline
# -*- coding: utf-8 -*-
"""
Agent3 (í†µí•© íŒŒì´í”„ë¼ì¸)
- Agent 1 ë¡œì§: í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì…ë ¥ â†’ ì˜ì–´ ë²ˆì—­ (EXAONE)
- Agent 2 ë¡œì§: ì´ë¯¸ì§€ ê²½ë¡œ ì…ë ¥ â†’ ì˜ì–´ ìº¡ì…˜ (Ollama Gemma3)
- Agent 3 ë¡œì§ (1): ë‘ ì˜ì–´ ë¬¸ì¥ â†’ í•˜ë‚˜ì˜ ë¬¸ì¥ìœ¼ë¡œ ì¬ì‘ì„± (Ollama Gemma3)
- Agent 3 ë¡œì§ (2): ì¬ì‘ì„±ëœ ë¬¸ì¥ â†’ ì˜ì–´ í‚¤ì›Œë“œ 5ê°œ ì¶”ì¶œ (Ollama Gemma3)
- ì„¸ì…˜ ê´€ë¦¬: ëª¨ë“  ê²°ê³¼ë¥¼ 'active_session.json'ì— ëˆ„ì  ì €ì¥
- Agent 4 ë¡œì§: ìœ„ì¹˜ + ì´ë¯¸ì§€ + ì£¼ë³€ ìŒì•… ê¸°ë°˜ ì¶”ì²œ íŒŒì´í”„ë¼ì¸ (recommend_with_image_and_nearby_users)
"""

import os
import re
import json
from datetime import datetime
import requests
import uuid
from collections import OrderedDict # CLI ë¡œì§ì—ì„œ í•„ìš”

# agent1 import
try:
    from agent1_exaone import korean_to_english
except ImportError:
    print("âŒ 'agents/agent1_exaone.py' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit()

# agent2 import
try:
    from agent2_imageToEng import image_to_english_caption, caption_from_base64, enhance_caption_with_location
except ImportError:
    print("âŒ 'agents/agent2_imageToEng.py' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit()
    
# rag import
try:
    from context_manager import get_full_conversation_history
except ImportError:
    print("âŒ 'agents/context_manager.py' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit()
    
# rag retriever - song recommendation import
try:
    from rag_retriever import get_song_recommendations, get_vector_db, embed_text
except ImportError:
    print("âŒ 'rag/rag_retriever.py' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit()
        
# =========================================================
# 1. ì „ì—­ ì„¤ì •
# =========================================================
OLLAMA_URL = "http://localhost:11434"
GEMMA3_MODEL = "gemma3:4b"
SAVE_DIR = "agents/keywords"
os.makedirs(SAVE_DIR, exist_ok=True)

# =========================================================
# 3. [Agent 3-1] ë‘ ì˜ì–´ ë¬¸ì¥ í•©ì¹˜ê¸° : ëª¨ë¸ ì•ˆì“°ê³  ê·¸ëƒ¥ ë¬¸ì¥ í•©ì¹ ì§€ ê³ ë¯¼ì¤‘
# =========================================================
def rewrite_combined_sentence(text1: str, text2: str, full_history: str) -> str:    
    new_input_sentence = f"{text1} {text2}".strip()
    if not new_input_sentence:
        # (ì˜ˆ: "ë¹„ ì˜¤ëŠ” ë‚ " -> "ë” ì°¨ë¶„í•˜ê²Œ")
        # ìƒˆ ì…ë ¥(text1, text2)ì´ ì—†ë”ë¼ë„, ì´ì „ ì´ë ¥(full_history)ë§Œìœ¼ë¡œ
        # Gemma3ê°€ í‚¤ì›Œë“œë¥¼ ë‹¤ì‹œ ìƒì„±í•˜ë„ë¡ ìœ ë„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        # í•˜ì§€ë§Œ ì—¬ê¸°ì„œëŠ” ìƒˆ ì…ë ¥ì´ ì—†ìœ¼ë©´ ì—ëŸ¬ë¡œ ê°„ì£¼í•˜ê³  ë¹ˆ ë¬¸ìì—´ ë°˜í™˜
        print("âš ï¸ [Agent 3] No new input text or image provided.")
        return ""

    print("ğŸ§© [Agent 3] Merging (Context + New Input) sentences (Ollama)...")
    # [í•µì‹¬] ğŸ‘ˆ Gemma3ì—ê²Œ 'ì´ì „ ëŒ€í™”'ì™€ 'ìƒˆ ìš”ì²­'ì„ í•¨ê»˜ ì „ë‹¬
    prompt = f"""
You are a context-aware chat assistant. Your job is to understand the user's full request by combining their past conversation history with their newest input.

[Past Conversation History]
{full_history}

[User's Newest Input]
"{new_input_sentence}"

Task:
Create ONE final descriptive sentence that reflects only the user's latest intention.

Rules:
1. Past history is for reference.
2. The newest input overrides or replaces previous intent if different.
3. Do NOT preserve previous meanings when the new input changes the mood/direction.
4. Focus on the newest input as the dominant signal.

Respond *only* with the final combined English sentence.
"""
    
    messages = [{"role": "user", "content": prompt.strip()}]
    payload = {"model": GEMMA3_MODEL, "messages": messages, "stream": False}
    try:
        res = requests.post(f"{OLLAMA_URL}/api/chat", json=payload, timeout=60)
        res.raise_for_status()
        
        raw_response = (res.json().get("message", {}).get("content", "") or "").strip()
        match = re.search(r'["\'](.*?_*)["\']', raw_response)
        if match:
            return match.group(1).strip()
        return raw_response.split('\n')[-1].strip()
        
    except Exception as e:
        print(f"âš ï¸ Merge failed: {e}")
        return new_input_sentence # ì‹¤íŒ¨ ì‹œ ìƒˆ ì…ë ¥ë§Œ ë°˜í™˜
    
def extract_keywords(merged_text: str, full_history: str, k: int = 5) -> list[str]:
    if not merged_text.strip():
        return []

    system_prompt = f"""
You are a Music Context Understanding & Keyword Extraction Expert.
Extract EXACTLY {k} keywords that best represent the user's musical intent.

### STRICT RULES ###

1. **Primary Subject / Setting (NOUNS)** - If the sentence includes a main noun (night, rain, drive, study, winter, ocean, city), 
     include EXACTLY ONE such noun as the FIRST keyword.
   - Do NOT stop at only one keyword. It only defines the *first* slot.

2. **Sound Texture (Adjective or Style Words)** - Fill at least 1â€“2 of the remaining keywords with sound-related adjectives  
     (soft, acoustic, ambient, mellow, electronic, jazzy, gentle).

3. **Emotional Vibe (Feels / Mood)** - Include at least 1 emotional keyword  
     (calm, sweet, dreamy, nostalgic, romantic, angry, peaceful).

4. **User Expression Preservation (Non-musical expressions allowed)** - If the user expresses feelings like â€œë‹¬ë‹¬í•œâ€, â€œì§œì¦ë‚˜ëŠ”â€, â€œë”°ëœ»í•œâ€,  
     you MUST include the English equivalent in the final keywords  
     (sweet, irritated, warm, refreshing).

5. **ABSOLUTE RULE** - You MUST output **exactly {k} keywords**, no fewer.  
   - If fewer than {k} suitable terms exist, expand using closely-related semantic descriptors.  
   - NEVER output only one keyword.

Output ONLY valid JSON:
{{"keywords": ["k1", "k2", "k3", "k4", "k5"]}}
"""

    user_prompt = f"""
Past conversation:
{full_history}

User's latest intent:
"{merged_text}"

Extract the final {k} refined keywords following all rules above.
"""

    payload = {
        "model": GEMMA3_MODEL,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        "stream": False,
        "format": "json"
    }

    try:
        res = requests.post(f"{OLLAMA_URL}/api/chat", json=payload, timeout=60)
        res.raise_for_status()

        raw_output = (
            res.json().get("message", {}).get("content")
            or res.json().get("response")
            or ""
        ).strip()

        parsed = json.loads(raw_output)
        kws = parsed.get("keywords", [])

        # Clean
        clean = []
        for w in kws:
            w = re.sub(r"[^a-zA-Z]", "", w.lower())
            if 2 <= len(w) <= 20:
                clean.append(w)

        # Ensure exactly k
        return list(dict.fromkeys(clean))[:k]

    except Exception as e:
        print(f"ğŸ”¥ Keyword extraction failed: {e}")
        return ["night", "calm", "soft", "sweet", "ambient"][:k]

    
# =========================================================
# 8. ì„¸ì…˜ ì €ì¥ - ë‚˜ì˜ ìˆœê°„
# =========================================================
def save_to_session_simple(data: dict, session_file: str):
    """
    ì§€ì •ëœ ì„¸ì…˜ JSON íŒŒì¼ì„ ì•ˆì „í•˜ê²Œ ì—´ê³ , ë°ì´í„°ë¥¼ appendí•©ë‹ˆë‹¤.
    íŒŒì¼ì´ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.
    """
    default_structure = {
        "session_start": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "input_korean": [], "input_image": [],
        "english_text_from_agent1": [], "english_caption_from_agent2": [],
        "merged_sentence": [], "english_keywords": [],
        "recommended_songs": []
    }
    
    if os.path.exists(session_file):
        try:
            with open(session_file, "r", encoding="utf-8") as f:
                session_data = json.load(f)
            for key, default_value in default_structure.items():
                if key not in session_data:
                    session_data[key] = default_value
        except json.JSONDecodeError:
            print(f"âš ï¸ ì„¸ì…˜ íŒŒì¼ì´ ì†ìƒë˜ì–´ ìƒˆë¡œ ë§Œë“­ë‹ˆë‹¤: {session_file}")
            session_data = default_structure
    else:
        session_data = default_structure

    try:
        session_data["input_korean"].append(data["input"]["korean_text"])
        session_data["input_image"].append(data["input"]["image_path"])
        session_data["english_text_from_agent1"].append(data["english_text_from_agent1"])
        session_data["english_caption_from_agent2"].append(data["english_caption_from_agent2"])
        session_data["merged_sentence"].append(data["merged_sentence"])
        session_data["english_keywords"].append(data["english_keywords"])
        session_data["recommended_songs"].append(data["recommended_songs"])
        
        # â• ì¶”ê°€: track_id ëˆ„ì  ì €ì¥
        if "recommended_track_ids" not in session_data:
            session_data["recommended_track_ids"] = []

        for song in data["recommended_songs"]:
            tid = song.get("track_id")
            if tid and tid not in session_data["recommended_track_ids"]:
                session_data["recommended_track_ids"].append(tid)
                
    except KeyError as e:
        print(f"ğŸ”¥ ë°ì´í„° ì €ì¥ ì¤‘ ì¹˜ëª…ì ì¸ Key Error ë°œìƒ: {e}")
        return

    with open(session_file, "w", encoding="utf-8") as f:
        json.dump(session_data, f, ensure_ascii=False, indent=2)
        
# =========================================================
# ì„¸ì…˜ ì €ì¥ - ë‚˜ì˜ ê³µê°„
def save_location_recommend_full(data: dict):
    """
    Agent4 ì¶”ì²œ ê²°ê³¼ë¥¼ ì „ì²´ ì„¸ì…˜ í˜•ì‹ìœ¼ë¡œ ì§€ì •ëœ ê²½ë¡œì— ì €ì¥í•©ë‹ˆë‹¤.
    ì €ì¥ ê²½ë¡œ: ai/agents/location_recommends/
    """
    
    # 1. ì €ì¥ ë””ë ‰í† ë¦¬ ì„¤ì • ë° ìƒì„±
    # SAVE_DIR = "agents/keywords"ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•˜ì—¬, location_recommends í´ë”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    location_save_dir = os.path.join("agents", "location_recommends")
    os.makedirs(location_save_dir, exist_ok=True)
    
    # 2. íŒŒì¼ëª… ìƒì„± (ë‚˜ì˜ ìˆœê°„ê³¼ ë™ì¼í•œ í˜•ì‹)
    random_id=str(uuid.uuid4())[:8]
    file_name = f"location_recommend_{random_id}.json"
    save_path = os.path.join(location_save_dir, file_name)
    
    input_data = data.get("input", {}) # 'input' í‚¤ê°€ ì—†ì„ ê²½ìš° ëŒ€ë¹„

    # 3. JSON ì €ì¥
    with open(save_path, "w", encoding="utf-8") as f:
        # Agent4 ê²°ê³¼ëŠ” ë‹¨ì¼ í˜¸ì¶œì´ë¯€ë¡œ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ë‹¨ì¼ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ì €ì¥í•©ë‹ˆë‹¤.
        # ì„¸ì…˜ êµ¬ì¡°ì™€ í˜•ì‹ì€ ê°™ë˜, ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¥¼ ë‹¨ì¼ ê°’ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥ (ì„ íƒì )
        output_data = {
            "timestamp": data.get("timestamp"),
            "input_location": input_data.get("location"),
            "input_image": input_data.get("image_path", ""),
            "english_caption_from_agent2": data.get("english_caption_from_agent2"),
            "english_keywords": data.get("english_keywords"),
            "recommended_songs": data.get("recommended_songs"),
        }
        json.dump(output_data, f, ensure_ascii=False, indent=2)

    print(f"ğŸ’¾ Saved location recommend result â†’ {save_path}")
    return save_path
        
# -------------------------------------------------------
# ì£¼ë³€ ì‚¬ëŒì´ ë“£ëŠ” ë…¸ë˜ë¥¼ RAG DBì—ì„œ ë§¤ì¹­
# -------------------------------------------------------
def match_song_in_rag(title: str, artist: str, top_k=1):
    """
    ì£¼ë³€ ì‚¬ëŒì´ ë“£ëŠ” ë…¸ë˜(title, artist)ë¥¼ í•˜ë‚˜ì˜ ë¬¸ì¥ìœ¼ë¡œ ë¬¶ì–´ì„œ
    RAG DBì—ì„œ ê°€ì¥ ìœ ì‚¬í•œ Jamendo ë…¸ë˜ë¥¼ ê²€ìƒ‰í•œë‹¤.
    """
    db = get_vector_db()  # Chroma DB
    query = f"{title} {artist}"

    query_vec = embed_text(query)

    results = db.similarity_search_with_score(query, k=top_k)

    matched = []
    for r, score in results:
        meta = r.metadata
        meta["similarity_score"] = score
        matched.append(meta)

    return matched


# -------------------------------------------------------
# ì£¼ë³€ ìŒì•… ê¸°ë°˜ìœ¼ë¡œ ìœ ì‚¬ ë…¸ë˜ ì°¾ê¸°
# -------------------------------------------------------
def recommend_from_nearby_music(nearbyMusic: list):
    """
    ê° ì£¼ë³€ ìŒì•…ì„ RAG DBì—ì„œ ë§¤ì¹­ â†’ ìœ ì‚¬í•œ ë…¸ë˜ ì¶”ì²œ
    """
    all_recs = []

    for m in nearbyMusic:
        # **[ìˆ˜ì •]** CLIì™€ APIì˜ í‚¤ë¥¼ í†µì¼í•˜ì—¬ 'title', 'artist' ì‚¬ìš©
        title = m.get("title", "") 
        artist = m.get("artist", "")

        # songTitle, artistNameìœ¼ë¡œ ë“¤ì–´ì˜¬ ê²½ìš° (ì´ì „ CLI ì½”ë“œì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€)
        if not title:
             title = m.get("songTitle", "") 
        if not artist:
            artist = m.get("artistName", "")

        if not title and not artist:
            continue
            
        # 1) RAG DBì—ì„œ K-pop â†’ Jamendo ê³¡ ë§¤ì¹­
        matched = match_song_in_rag(title, artist, top_k=1)
        if not matched:
            continue

        anchor_song = matched[0]
        print(f"ğŸ§ Anchor Matched â†’ {anchor_song['track_name']} / {anchor_song['artist_name']}")

        # 2) í•´ë‹¹ Jamendo ê³¡ê³¼ ìœ ì‚¬í•œ ìŒì•… ì¶”ê°€ ì¶”ì²œ
        anchor_keywords = [
            anchor_song.get("genre_tags", ""),
            anchor_song.get("mood_tags", ""),
            anchor_song.get("track_name", "")
        ]
        anchor_keywords = " ".join(anchor_keywords)

        recs = get_song_recommendations(anchor_keywords.split(), top_k=2)
        all_recs.extend(recs)

    # ì¤‘ë³µ ì œê±°
    seen = set()
    unique = []
    for r in all_recs:
        tid = r["track_id"]
        if tid not in seen:
            seen.add(tid)
            unique.append(r)

    return unique


# # -------------------------------------------------------
# # ë©”ì¸ ì¶”ì²œ: ì´ë¯¸ì§€ + ì£¼ë³€ ìŒì•…
# # -------------------------------------------------------
# def recommend_with_image_and_nearby_users(image_b64: str,
#                                           place_name: str,
#                                           nearbyMusic: list):

#     # 1) ì´ë¯¸ì§€ â†’ ìº¡ì…˜
#     caption = caption_from_base64(image_b64)
#     print("ğŸ“· Caption:", caption)

#     # 2) ì¥ì†Œ ê¸°ë°˜ ë³´ì •
#     enhanced_caption = enhance_caption_with_location(caption, place_name)
#     print("ğŸ“ Enhanced Caption:", enhanced_caption)

#     # 3) ì´ë¯¸ì§€ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ
#     user_keywords = extract_keywords(
#         merged_text=enhanced_caption,
#         full_history="",
#         k=5
#     )
#     print("ğŸ¨ Image Keywords:", user_keywords)

#     # 4) ì´ë¯¸ì§€ ê¸°ë°˜ ì¶”ì²œ
#     img_recs = get_song_recommendations(user_keywords, top_k=2)

#     # 5) ì£¼ë³€ ìŒì•… ê¸°ë°˜ ì¶”ì²œ
#     near_recs = recommend_from_nearby_music(nearbyMusic)

#     # 6) ë‘ ì¶”ì²œ ë¦¬ìŠ¤íŠ¸ í•©ì³ì„œ ìµœì¢… 3ê³¡ë§Œ
#     combined = img_recs + near_recs

#     # ì¤‘ë³µ ì œê±°
#     seen = set()
#     final = []
#     for r in combined:
#         tid = r["track_id"]
#         if tid not in seen:
#             seen.add(tid)
#             final.append(r)
#         if len(final) >= 1:
#             break

#     return {
#         "caption": enhanced_caption,
#         "keywords": user_keywords,
#         "recommended_songs": final
#     }

# ì €ì¥ ì½”ë“œ
def save_location_recommend(result: dict):
    """
    Agent4 ì¶”ì²œ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥. (ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” ë ˆê±°ì‹œ í•¨ìˆ˜ì¼ ìˆ˜ ìˆìŒ)
    ì €ì¥ íŒŒì¼ëª…: location_recommend_YYYYmmdd_HHMMSS.json
    """
    save_path = os.path.join(
        SAVE_DIR,
        f"location_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    )

    # recommended_songsëŠ” 1ê³¡ë§Œ ì˜¨ë‹¤ëŠ” ì „ì œ
    if not result.get("recommended_songs"):
        print("âŒ No recommended songs to save.")
        return None

    # **[ìˆ˜ì •]** recommended_songsì˜ ëª¨ë“  ê³¡ì„ ì €ì¥í•˜ë„ë¡ ë³€ê²½ (ê¸°ì¡´: 1ê³¡ë§Œ ì €ì¥)
    output_json = {
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "recommendations": []
    }
    
    for song in result["recommended_songs"]:
        output_json["recommendations"].append({
            "songId": song.get("track_id"),
            "title": song.get("track_name"),
            "artist": song.get("artist_name"),
            "durationMs": int(song.get("duration", 0) * 1000),  # ì´ˆ â†’ ms ë³€í™˜
            "trackUrl": song.get("url")
        })


    with open(save_path, "w", encoding="utf-8") as f:
        json.dump(output_json, f, ensure_ascii=False, indent=2)

    print(f"ğŸ’¾ Saved recommend result â†’ {save_path}")
    return save_path


# nearby_users.json ì½ì–´ì˜¤ê¸°
def load_nearby_users_json():
    path = "agents/nearby_users.json"
    if not os.path.exists(path):
        print("âŒ nearby_users.json íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return None

    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)
    
    
def run_location_recommendation():
    """
    nearby_users.json ì„ ì½ì–´ì„œ:
    - imagePath ê¸°ë°˜ ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„±
    - ì£¼ë³€ ì‚¬ìš©ì ë…¸ë˜ ê¸°ë°˜ ì¶”ì²œ
    """
    payload = load_nearby_users_json()
    if payload is None:
        raise ValueError("nearby_users.json ë¡œë”© ì‹¤íŒ¨")

    image_path = payload.get("imagePath")
    nearbyMusic = payload.get("nearbyMusic", [])

    if not image_path:
        raise ValueError("âŒ nearby_users.json ì— 'imagePath'ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # 1) ì´ë¯¸ì§€ â†’ ìº¡ì…˜
    caption = image_to_english_caption(image_path)

    # ì¥ì†Œ ë³´ì • ì—†ìŒ
    enhanced_caption = caption

    # 2) í‚¤ì›Œë“œ ì¶”ì¶œ
    keywords = extract_keywords(enhanced_caption, full_history="", k=5)

    # 3) ì´ë¯¸ì§€ ê¸°ë°˜ ì¶”ì²œ
    img_recs = get_song_recommendations(keywords, top_k=3)

    # 4) ì£¼ë³€ ì‚¬ìš©ì ê¸°ë°˜ ì¶”ì²œ
    near_recs = recommend_from_nearby_music(nearbyMusic)

    # 5) ìµœì¢… 1ê³¡ ì„ íƒ
    combined = img_recs + near_recs
    final = []
    seen = set()

    for r in combined:
        tid = r["track_id"]
        if tid not in seen:
            seen.add(tid)
            final.append(r)
        if len(final) == 1:
            break

    return {
        "caption": enhanced_caption,
        "keywords": keywords,
        "nearby_users": nearbyMusic,
        "image_path": image_path,
        "recommended_songs": final
    }


# =========================================================
# 9. ë©”ì¸ íŒŒì´í”„ë¼ì¸
# =========================================================
def run_agent_pipeline(korean_text="", image_path="", location_payload=None) -> dict:    
    
    # 1) ìœ„ì¹˜ ê¸°ë°˜ ë¶„ì„ ìš”ì²­ì´ë©´, Agent4 ì‹¤í–‰
    if location_payload:
        print("ğŸ“ Running Location-Based Recommendation (Agent4 Mode)")
        result = run_location_recommendation()
        
        # ì €ì¥ êµ¬ì¡°ëŠ” ê¸°ì¡´ì²˜ëŸ¼ ìœ ì§€
        data = {
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "input": {
                "korean_text": "ì´ë¯¸ì§€ + ì£¼ë³€ ì‚¬ìš©ì ê¸°ë°˜ ì¶”ì²œ ìš”ì²­",
                "image_path": result["image_path"]
            },
            "english_caption_from_agent2": result["caption"],
            "english_keywords": result["keywords"],
            "recommended_songs": result["recommended_songs"]
        }

        save_location_recommend_full(data)
        return data
    
    # ----------- ì¼ë°˜ í…ìŠ¤íŠ¸/ì´ë¯¸ì§€ ê¸°ë°˜ ì¶”ì²œ íë¦„ -----------

    # ì„¸ì…˜ íŒŒì¼ ê²½ë¡œ
    session_file_path = os.path.join(SAVE_DIR, "active_session.json")

    # ëŒ€í™” ì´ë ¥ ë¶ˆëŸ¬ì˜¤ê¸° (RAGìš©)
    full_history = get_full_conversation_history(session_file_path)

    # Agent1: í•œêµ­ì–´ â†’ ì˜ì–´ ë²ˆì—­
    english_text = korean_to_english(korean_text) if korean_text else ""

    # Agent2: ì´ë¯¸ì§€ â†’ ì˜ì–´ ìº¡ì…˜
    english_caption = image_to_english_caption(image_path) if image_path else ""

    # Agent3-1: ë¬¸ì¥ í•©ì¹˜ê¸°
    merged = rewrite_combined_sentence(english_text, english_caption, full_history)

    # Agent3-2: í‚¤ì›Œë“œ ì¶”ì¶œ
    eng_keywords = extract_keywords(merged, full_history)

    # ğŸµ ë…¸ë˜ ì¶”ì²œ: ì´ˆê¸°ì— ë„‰ë„‰í•˜ê²Œ ê°€ì ¸ì˜¤ê¸° (ì¤‘ë³µ ì œê±° ëŒ€ë¹„)
    recommended_songs = get_song_recommendations(eng_keywords, top_k=15)

    # --------------- ğŸ“Œ í•„í„°ë§ ë¡œì§ ì‹œì‘ ---------------

    # 1) Fly í¬í•¨ëœ ì•¨ë²” ì œê±°
    recommended_songs = [
        s for s in recommended_songs
        if "fly" not in s.get("album_name", "").lower()
    ]

    # 2) ì´ë¯¸ ì¶”ì²œëœ ê³¡ ì œê±°
    try:
        with open(session_file_path, "r", encoding="utf-8") as f:
            session_data = json.load(f)
        already = set(session_data.get("recommended_track_ids", []))
    except FileNotFoundError:
        already = set()

    recommended_songs = [
        s for s in recommended_songs
        if s.get("track_id") not in already
    ]

    # 3) fallback: í•„í„°ë§ìœ¼ë¡œ ë„ˆë¬´ ì¤„ì–´ë“  ê²½ìš° ë‹¤ì‹œ ì°¾ê¸°
    if len(recommended_songs) < 3:
        fallback = get_song_recommendations(eng_keywords, top_k=40)
        fallback = [
            s for s in fallback
            if "fly" not in s.get("album_name", "").lower()
            and s.get("track_id") not in already
        ]
        recommended_songs = fallback[:3]

    else:
        recommended_songs = recommended_songs[:3]

    # --------------- ğŸ“Œ í•„í„°ë§ ë¡œì§ ë ---------------

    # ìµœì¢… ë°ì´í„° íŒ¨í‚¤ì§•
    data = {
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "input": {"korean_text": korean_text, "image_path": image_path},
        "english_text_from_agent1": english_text,
        "english_caption_from_agent2": english_caption,
        "merged_sentence": merged,
        "english_keywords": eng_keywords,
        "recommended_songs": recommended_songs,
    }

    # ì„¸ì…˜ì— ì €ì¥
    save_to_session_simple(data, session_file_path)
    print(f"\nâœ… Saved to active session â†’ {session_file_path}")

    return data

# =========================================================
# 7ï¸âƒ£ CLI (ì„¸ì…˜ ê´€ë¦¬ì)
# =========================================================
# base64ëŠ” íŒŒì¼ ìƒë‹¨ì— ì´ë¯¸ import ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ìƒëµí•©ë‹ˆë‹¤.

if __name__ == "__main__":
    print("\nğŸ¤– Agent Pipeline (ì„¸ì…˜í˜• ì‹¤í–‰)")

    active_session_path = os.path.join(SAVE_DIR, "active_session.json")
    # ì„¸ì…˜ ì‹œì‘/ì´ì–´í•˜ê¸° ì§ˆë¬¸ì€ ìœ ì§€
    choice = input("\nìƒˆ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ë ¤ë©´ 'new' ì…ë ¥ (ê¸°ì¡´ ì´ì–´í•˜ê¸°ëŠ” Enter): ").strip().lower()

    # ... (ê¸°ì¡´ ì„¸ì…˜ ì•„ì¹´ì´ë¹™ ë° ìƒˆ ì„¸ì…˜ ì‹œì‘ ë¡œì§ì€ ë™ì¼)
    if choice == "new":
        # 1) ê¸°ì¡´ active_session.json ë°±ì—…
        if os.path.exists(active_session_path):
            try:
                with open(active_session_path, "r", encoding="utf-8") as f:
                    old_data = json.load(f)
                end_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                old_data["session_end"] = end_time

                archive_name = f"session_{uuid.uuid4().hex[:6]}.json"
                archive_path = os.path.join(SAVE_DIR, archive_name)

                with open(archive_path, "w", encoding="utf-8") as f:
                    json.dump(old_data, f, ensure_ascii=False, indent=2)

                print(f"ğŸ—‚ï¸ ì„¸ì…˜ ë³´ê´€ ì™„ë£Œ: {archive_name} (session_end: {end_time})")

            except Exception as e:
                print(f"âš ï¸ ì„¸ì…˜ ì•„ì¹´ì´ë¹™ ì˜¤ë¥˜: {e}")

            # 2) ğŸ”¥ ì´ ì¤„ì´ ìƒˆë¡œìš´ ì„¸ì…˜ì´ ì •ìƒ ìƒì„±ë˜ê²Œ í•˜ëŠ” í•µì‹¬!
            os.remove(active_session_path)

        # 3) ìƒˆë¡œìš´ ì„¸ì…˜ íŒŒì¼ ìƒì„±
        new_session = {
            "session_id": uuid.uuid4().hex[:6],
            "session_start": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "input_korean": [],
            "input_image": [],
            "english_text_from_agent1": [],
            "english_caption_from_agent2": [],
            "merged_sentence": [],
            "english_keywords": [],
            "recommended_songs": []
        }

        with open(active_session_path, "w", encoding="utf-8") as f:
            json.dump(new_session, f, ensure_ascii=False, indent=2)

        print(f"ğŸ†• ìƒˆ ì„¸ì…˜ ìƒì„± ì™„ë£Œ!")


    # ------------------------------------------------
    # âœ¨ ëª¨ë“œ ì„ íƒ ë¡œì§ ì¶”ê°€
    # ------------------------------------------------
    print("\n--- ğŸŒŸ ì‹¤í–‰ ëª¨ë“œ ì„ íƒ ---")
    mode = input("1. ì¼ë°˜ í…ìŠ¤íŠ¸/ì´ë¯¸ì§€ ì…ë ¥ (ì„¸ì…˜ ê¸°ë°˜)\n2. ìœ„ì¹˜ ê¸°ë°˜ ì¶”ì²œ (Agent4)\nì„ íƒ (1 ë˜ëŠ” 2): ").strip()
    
    if mode == "2":
        print("\n--- ğŸ“ ìœ„ì¹˜ ê¸°ë°˜ ì¶”ì²œ (Agent4) ì‹¤í–‰ ---")

        try:
            with open("agents/nearby_users.json", "r", encoding="utf-8") as f:
                payload = json.load(f)

            image_path = payload.get("imagePath")
            nearbyMusic = payload.get("nearbyMusic", [])

        except Exception as e:
            print(f"âŒ nearby_users.json ì½ê¸° ì˜¤ë¥˜: {e}")
            exit()

        print("ğŸ“„ nearby_users.json ë¡œë“œ ì™„ë£Œ")
        print(f" - ì´ë¯¸ì§€ ê²½ë¡œ: {image_path}")
        print(f" - ì£¼ë³€ ì‚¬ìš©ì ìŒì•… ê°œìˆ˜: {len(nearbyMusic)}")

        try:
            print("\n--- ğŸš€ Agent4 íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ---")

            caption = image_to_english_caption(image_path)
            keywords = extract_keywords(caption, full_history="", k=5)

            img_recs = get_song_recommendations(keywords, top_k=3)
            near_recs = recommend_from_nearby_music(nearbyMusic)

            combined = img_recs + near_recs
            final = []
            seen = set()

            for r in combined:
                tid = r["track_id"]
                if tid not in seen:
                    seen.add(tid)
                    final.append(r)
                if len(final) == 1:
                    break

            result = {
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "input": {
                    "korean_text": "nearby_users.json ê¸°ë°˜ ìœ„ì¹˜ ì¶”ì²œ",
                    "image_path": image_path
                },
                "english_caption_from_agent2": caption,
                "english_keywords": keywords,
                "recommended_songs": final
            }

            save_location_recommend_full(result)

            print("\n--- ğŸ¯ ì‹¤í–‰ ê²°ê³¼ (Agent4) ---")
            print(json.dumps(result, ensure_ascii=False, indent=2))

        except Exception as e:
            print(f"ğŸ”¥ Agent4 ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

            
    else: 
        # 1ë²ˆ ë˜ëŠ” ì˜ëª»ëœ ì…ë ¥ (ê¸°ë³¸ê°’: ì¼ë°˜ í…ìŠ¤íŠ¸/ì´ë¯¸ì§€ ëª¨ë“œ)
        print("\n--- ğŸ’¬ ì¼ë°˜ í…ìŠ¤íŠ¸/ì´ë¯¸ì§€ ì…ë ¥ (ì„¸ì…˜ ê¸°ë°˜) ---")
        text = input("í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì…ë ¥ (ì—†ìœ¼ë©´ Enter): ").strip()
        img = input("ì´ë¯¸ì§€ ê²½ë¡œ ì…ë ¥ (ì—†ìœ¼ë©´ Enter): ").strip()

        if not text and not img:
            print("\nğŸ›‘ ì…ë ¥ì´ ì—†ì–´ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            exit()

        print("\n--- ğŸš€ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ---")
        try:
            # run_agent_pipelineì— í…ìŠ¤íŠ¸/ì´ë¯¸ì§€ ê²½ë¡œ ì „ë‹¬
            result = run_agent_pipeline(korean_text=text, image_path=img)
            print("\n--- ğŸ¯ ì‹¤í–‰ ê²°ê³¼ ---")
            print(json.dumps(result, ensure_ascii=False, indent=2))
        except Exception as e:
            print(f"\nğŸ”¥ ì˜¤ë¥˜ ë°œìƒ: {e}")